\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}System Overview (75 pts)}{2}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}NetHandler Class}{2}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Request Class}{2}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Linked Blocking Queue}{2}{subsection.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Worker Class}{2}{subsection.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A view of the middleware system and its components. The blue rectangles represent the Java objects which are parts of the middleware. The black arrows represent object creations. The green and beige rectangles represent the client VMs and server VMs, respectively. The purple arrows show the path a request takes through the system. A request is initially sent by the client to the middleware, where it is handled by the NetHandler. It is then added to the request queue where it waits for an available worker. A worker removes the request from the queue, forwards it to one or more servers and awaits the server response before finally responding to the client according to the server response. At shut down the middleware creates a StatisticsHandler which gathers statistics from all Workers, aggragates them and writes them to files.\relax }}{3}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:system_diagram}{{1}{3}{A view of the middleware system and its components. The blue rectangles represent the Java objects which are parts of the middleware. The black arrows represent object creations. The green and beige rectangles represent the client VMs and server VMs, respectively. The purple arrows show the path a request takes through the system. A request is initially sent by the client to the middleware, where it is handled by the NetHandler. It is then added to the request queue where it waits for an available worker. A worker removes the request from the queue, forwards it to one or more servers and awaits the server response before finally responding to the client according to the server response. At shut down the middleware creates a StatisticsHandler which gathers statistics from all Workers, aggragates them and writes them to files.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A view of the paths a request takes through the middleware. The black arrows represent the paths a request takes. The blue rectangles represent the Java objects which are parts of the middleware. The beige rectangles represent function calls of those objects. In the case of branching paths, the type of request and whether \texttt  {sharded=true} determines which path is chosen. The servers are not shown on this diagram for the sake of clarity. Server communication takes place within the \texttt  {SendGet}, \texttt  {SendSet} and \texttt  {SendSharded} functions of the worker class.\relax }}{4}{figure.caption.2}}
\newlabel{fig:request_paths}{{2}{4}{A view of the paths a request takes through the middleware. The black arrows represent the paths a request takes. The blue rectangles represent the Java objects which are parts of the middleware. The beige rectangles represent function calls of those objects. In the case of branching paths, the type of request and whether \texttt {sharded=true} determines which path is chosen. The servers are not shown on this diagram for the sake of clarity. Server communication takes place within the \texttt {SendGet}, \texttt {SendSet} and \texttt {SendSharded} functions of the worker class.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1}Handling SET-requests}{4}{subsubsection.1.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.2}Handling GET-requests}{4}{subsubsection.1.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.3}Handling Sharded MultiGet-Requests}{5}{subsubsection.1.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.4}Statistics}{5}{subsubsection.1.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.5}Server Service Time}{5}{subsubsection.1.4.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.6}Response Time}{5}{subsubsection.1.4.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}System Shut Down}{6}{subsection.1.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Baseline without Middleware (75 pts)}{7}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}One Server}{7}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Experiment 2.1: Throughput and response time for a read-only workload. In the upper graph the throughput according to the interactive law has been plotted in addition to the measured throughput. The measurements can be clearly seen to follow the interactive law.\relax }}{7}{figure.caption.3}}
\newlabel{fig:21get}{{3}{7}{Experiment 2.1: Throughput and response time for a read-only workload. In the upper graph the throughput according to the interactive law has been plotted in addition to the measured throughput. The measurements can be clearly seen to follow the interactive law.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Experiment 2.1: Throughput and response time for a write-only workload. In the upper graph the throughput according to the interactive law has been plotted in addition to the measured throughput. The measurements can be clearly seen to follow the interactive law.\relax }}{8}{figure.caption.4}}
\newlabel{fig:21set}{{4}{8}{Experiment 2.1: Throughput and response time for a write-only workload. In the upper graph the throughput according to the interactive law has been plotted in addition to the measured throughput. The measurements can be clearly seen to follow the interactive law.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Two Servers}{8}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Experiment 2.2: Throughput and response time for a read-only workload on the two server set up. In the upper graph the throughput according to the interactive law has been plotted in addition to the measured throughput. The measurements can be clearly seen to follow the interactive law.\relax }}{9}{figure.caption.5}}
\newlabel{fig:22get}{{5}{9}{Experiment 2.2: Throughput and response time for a read-only workload on the two server set up. In the upper graph the throughput according to the interactive law has been plotted in addition to the measured throughput. The measurements can be clearly seen to follow the interactive law.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Experiment 2.2: Throughput and response time for a write-only workload on the two server set up. In the upper graph the throughput according to the interactive law has been plotted in addition to the measured throughput. The measurements can be clearly seen to follow the interactive law.\relax }}{10}{figure.caption.6}}
\newlabel{fig:22set}{{6}{10}{Experiment 2.2: Throughput and response time for a write-only workload on the two server set up. In the upper graph the throughput according to the interactive law has been plotted in addition to the measured throughput. The measurements can be clearly seen to follow the interactive law.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Conclusion}{10}{subsection.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Experiment 3.1: Measured throughput and response time for a workload of only read requests. The middleware with 64 worker threads has the highest throughput and lowest response time. However, when the middleware with 64 workers goes into over-saturation phase, the throughput of the 32 thread system is still slowly rising. This suggests that while 64 threads may be optimal when it comes to maximum throughput, the 32 thread configuration may be more stable when the number of clients grows to above 48. This may be due to the added overhead of maintaining more threads.\relax }}{12}{figure.caption.7}}
\newlabel{fig:31_get}{{7}{12}{Experiment 3.1: Measured throughput and response time for a workload of only read requests. The middleware with 64 worker threads has the highest throughput and lowest response time. However, when the middleware with 64 workers goes into over-saturation phase, the throughput of the 32 thread system is still slowly rising. This suggests that while 64 threads may be optimal when it comes to maximum throughput, the 32 thread configuration may be more stable when the number of clients grows to above 48. This may be due to the added overhead of maintaining more threads.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Baseline with Middleware (90 pts)}{12}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}One Middleware}{12}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Experiment 3.1: Measured throughput and response time for a workload of only write requests. Similar to the result in the read-request experiments, the system with 64 threads has the highest throughput. However, unlike the write request case, the 64 thread middleware remains stable up until 80 clients, where our measurements end.\relax }}{13}{figure.caption.8}}
\newlabel{fig:31_set}{{8}{13}{Experiment 3.1: Measured throughput and response time for a workload of only write requests. Similar to the result in the read-request experiments, the system with 64 threads has the highest throughput. However, unlike the write request case, the 64 thread middleware remains stable up until 80 clients, where our measurements end.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Experiment 3.1: A comparison of each of the experiments throughput and the throughput given by the interactive law. Using the response time measurements from the middleware to calculate the interactive law throughput, the measurements are far off. However, when the latency between the client and middleware are added to the response time measurements the measurements are very close to the interactive law predicted throughput.\relax }}{14}{figure.caption.9}}
\newlabel{fig:31_interactive_law}{{9}{14}{Experiment 3.1: A comparison of each of the experiments throughput and the throughput given by the interactive law. Using the response time measurements from the middleware to calculate the interactive law throughput, the measurements are far off. However, when the latency between the client and middleware are added to the response time measurements the measurements are very close to the interactive law predicted throughput.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Interactive Law}{14}{subsubsection.3.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Bottleneck Analysis}{14}{subsubsection.3.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Experiment 3.2: Measured throughput and response time for a workload of only read requests. The middleware with 64 worker threads has the highest throughput and lowest response time while the 32 thread system come very close. A maximum throughput of 3894 req/s is measured.\relax }}{16}{figure.caption.10}}
\newlabel{fig:32_get}{{10}{16}{Experiment 3.2: Measured throughput and response time for a workload of only read requests. The middleware with 64 worker threads has the highest throughput and lowest response time while the 32 thread system come very close. A maximum throughput of 3894 req/s is measured.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Two Middlewares}{16}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Experiment 3.2: Measured throughput and response time for a workload of only write requests. Similar to the result in the read-request experiments, the system with 64 threads has the highest throughput. Similar to the case of the read-only workload, the 32 thread configuration behaves almost exactly like the 32 thread configuration. A maximum throughput of 6774 req/s is measured.\relax }}{17}{figure.caption.11}}
\newlabel{fig:32_set}{{11}{17}{Experiment 3.2: Measured throughput and response time for a workload of only write requests. Similar to the result in the read-request experiments, the system with 64 threads has the highest throughput. Similar to the case of the read-only workload, the 32 thread configuration behaves almost exactly like the 32 thread configuration. A maximum throughput of 6774 req/s is measured.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Experiment 3.2: A comparison of each of the experiments throughput and the throughput given by the interactive law. Using the response time measurements from the middleware to calculate the interactive law throughput, the measurements are far off. However, when the latency between the client and middleware are added to the response time measurements the measurements are very close to the interactive law predicted throughput.\relax }}{18}{figure.caption.12}}
\newlabel{fig:32_interactive_law}{{12}{18}{Experiment 3.2: A comparison of each of the experiments throughput and the throughput given by the interactive law. Using the response time measurements from the middleware to calculate the interactive law throughput, the measurements are far off. However, when the latency between the client and middleware are added to the response time measurements the measurements are very close to the interactive law predicted throughput.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Bottleneck Analysis}{18}{subsubsection.3.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Experiment 3.3: The results of adding another client to the system. The highest throughput for read requests was 5818 req/s and for write requests a throughput of 10349.8 was achieved. While these numbers are quite a bit higher than what was achieved in earlier experiments (2.1, 3.1 and 3.2), it is important to note that the virtual machines were stopped and restarted before doing experiment 3.3. Therefore, the performance metrics are NOT directly comparable to those achieved earlier.\relax }}{19}{figure.caption.13}}
\newlabel{fig:33_max_config}{{13}{19}{Experiment 3.3: The results of adding another client to the system. The highest throughput for read requests was 5818 req/s and for write requests a throughput of 10349.8 was achieved. While these numbers are quite a bit higher than what was achieved in earlier experiments (2.1, 3.1 and 3.2), it is important to note that the virtual machines were stopped and restarted before doing experiment 3.3. Therefore, the performance metrics are NOT directly comparable to those achieved earlier.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Two Middlewares, Two Client VMs}{19}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Bottleneck Analysis}{19}{subsubsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Summary}{21}{subsection.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Experiment 4.1: Throughput for write-only workloads on the full system. As seen in the baselines before, the highest throughput is achieved with 64 worker threads, achieving a throughput of 6814 req/s.\relax }}{23}{figure.caption.14}}
\newlabel{fig:41_set}{{14}{23}{Experiment 4.1: Throughput for write-only workloads on the full system. As seen in the baselines before, the highest throughput is achieved with 64 worker threads, achieving a throughput of 6814 req/s.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Throughput for Writes (90 pts)}{23}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Full System}{23}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Experiment 4.1: Measured throughput for write-only workloads on the full system for all choices of worker threads. As can be seen in the table above, the middleware measured throughput is around 10\% lower than the throughput predicted by the interactive law. However, when comparing the response time measured in the middleware and in the clients difference of around 3 ms can be seen due to network effects. The interactive law plotted in these graphs have been calculated by adding 3 ms to all response times. This makes the interactive law fit better to the measured throughput. \relax }}{24}{figure.caption.15}}
\newlabel{fig:41_il}{{15}{24}{Experiment 4.1: Measured throughput for write-only workloads on the full system for all choices of worker threads. As can be seen in the table above, the middleware measured throughput is around 10\% lower than the throughput predicted by the interactive law. However, when comparing the response time measured in the middleware and in the clients difference of around 3 ms can be seen due to network effects. The interactive law plotted in these graphs have been calculated by adding 3 ms to all response times. This makes the interactive law fit better to the measured throughput. \relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Analysis}{25}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Experiment 5.1: Throughput and response times for multigets of various sizes in middleware with sharded GETs. Note how average response time rises linearly with key number. However the 99th percentile seems to rise sublinearly.\relax }}{27}{figure.caption.16}}
\newlabel{fig:51_all_req}{{16}{27}{Experiment 5.1: Throughput and response times for multigets of various sizes in middleware with sharded GETs. Note how average response time rises linearly with key number. However the 99th percentile seems to rise sublinearly.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Gets and Multi-gets (90 pts)}{27}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Sharded Case}{27}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Analysis}{28}{subsubsection.5.1.1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Utilization of components using sharded get requests.\relax }}{28}{table.caption.17}}
\newlabel{table:51_util}{{1}{28}{Utilization of components using sharded get requests.\relax }{table.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Non-sharded Case}{28}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Analysis}{28}{subsubsection.5.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Utilization of components using non-sharded get requests.\relax }}{28}{table.caption.19}}
\newlabel{table:52_util}{{2}{28}{Utilization of components using non-sharded get requests.\relax }{table.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Experiment 5.2: Throughput and response times for multigets of various sizes in middleware with non-sharded GETs. Note how average response time rises linearly with key number. In this case, the 90th and 99th percentiles rise slightly super-linearly compared to slightly sub-linearly in the sharded case.\relax }}{29}{figure.caption.18}}
\newlabel{fig:52_all_req}{{17}{29}{Experiment 5.2: Throughput and response times for multigets of various sizes in middleware with non-sharded GETs. Note how average response time rises linearly with key number. In this case, the 90th and 99th percentiles rise slightly super-linearly compared to slightly sub-linearly in the sharded case.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Histogram}{30}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Summary}{30}{subsection.5.4}}
\newlabel{fig7:a}{{18a}{31}{Sharded, Client measurements\relax }{figure.caption.20}{}}
\newlabel{sub@fig7:a}{{a}{31}{Sharded, Client measurements\relax }{figure.caption.20}{}}
\newlabel{fig7:b}{{18b}{31}{Sharded, Middleware measurements\relax }{figure.caption.20}{}}
\newlabel{sub@fig7:b}{{b}{31}{Sharded, Middleware measurements\relax }{figure.caption.20}{}}
\newlabel{fig7:c}{{18c}{31}{Non-Sharded, Client measurements\relax }{figure.caption.20}{}}
\newlabel{sub@fig7:c}{{c}{31}{Non-Sharded, Client measurements\relax }{figure.caption.20}{}}
\newlabel{fig7:d}{{18d}{31}{Non-Sharded, Middleware measurements\relax }{figure.caption.20}{}}
\newlabel{sub@fig7:d}{{d}{31}{Non-Sharded, Middleware measurements\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Comparison of response times gathered from client and middleware and for the case of sharded and non-sharded GET requests for 6 keys per GET request. Interestingly, the clients tend to measure slightly shorter response times. In all histograms we see two "bumps", the first centered around 2 ms and the second centered around 7 ms. These two bumps represent the two different request types for the mixed workload. The first bump represents SET requests which all contain one key and one value. The second bump represents the multi-GET requests which contain 6 keys. We notice a more equal spread for non-sharded request, that is higher variance in response time. This is due to the requests only being sent to one server in the non-sharded case. In the case of sharded requests, the request is sent to all servers and the response time must include the time it takes the last server to respond. It is clear that this measurement has less variance than the response time of a single server.\relax }}{31}{figure.caption.20}}
\newlabel{fig7}{{18}{31}{Comparison of response times gathered from client and middleware and for the case of sharded and non-sharded GET requests for 6 keys per GET request. Interestingly, the clients tend to measure slightly shorter response times. In all histograms we see two "bumps", the first centered around 2 ms and the second centered around 7 ms. These two bumps represent the two different request types for the mixed workload. The first bump represents SET requests which all contain one key and one value. The second bump represents the multi-GET requests which contain 6 keys. We notice a more equal spread for non-sharded request, that is higher variance in response time. This is due to the requests only being sent to one server in the non-sharded case. In the case of sharded requests, the request is sent to all servers and the response time must include the time it takes the last server to respond. It is clear that this measurement has less variance than the response time of a single server.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}2K Analysis (90 pts)}{32}{section.6}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The effects of each parameter in the 2K analysis in percentages. The parameters are: $W=$ number of worker threads, $S=$ number of servers and $M=$ number of middlewares. The variation due to the number of worker threads is in all cases the largest by far. The variation due to the number of middlewares is the second highest in all cases but much lower than the variation due to the number of worker threads. Variation due to interaction of parameters is in most cases insignificant. However, in the case of response times of GETs, the interaction of worker threads and middlewares reaches 10\%.\relax }}{32}{table.caption.21}}
\newlabel{table:2k}{{3}{32}{The effects of each parameter in the 2K analysis in percentages. The parameters are: $W=$ number of worker threads, $S=$ number of servers and $M=$ number of middlewares. The variation due to the number of worker threads is in all cases the largest by far. The variation due to the number of middlewares is the second highest in all cases but much lower than the variation due to the number of worker threads. Variation due to interaction of parameters is in most cases insignificant. However, in the case of response times of GETs, the interaction of worker threads and middlewares reaches 10\%.\relax }{table.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Queuing Model (90 pts)}{33}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}M/M/1}{33}{subsection.7.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Arrival rate ($\lambda $), Service rate ($\mu $) and traffic intensity ($\rho $)\relax }}{33}{table.caption.22}}
\newlabel{table:arrivalrate}{{4}{33}{Arrival rate ($\lambda $), Service rate ($\mu $) and traffic intensity ($\rho $)\relax }{table.caption.22}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Calculated output variables of the model\relax }}{33}{table.caption.23}}
\newlabel{table:mm1}{{5}{33}{Calculated output variables of the model\relax }{table.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}M/M/m}{33}{subsection.7.2}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Arrival rate ($\lambda $), Service rate ($\mu $) and traffic intensity ($\rho $)\relax }}{34}{table.caption.24}}
\newlabel{table:mmminput}{{6}{34}{Arrival rate ($\lambda $), Service rate ($\mu $) and traffic intensity ($\rho $)\relax }{table.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Calculated output variables of the M/M/m model\relax }}{34}{table.caption.25}}
\newlabel{table:mmmoutput}{{7}{34}{Calculated output variables of the M/M/m model\relax }{table.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Network of Queues}{34}{subsection.7.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Throughput of the model of experiment 3.1 for GET requests.\relax }}{35}{figure.caption.26}}
\newlabel{fig:71_get}{{19}{35}{Throughput of the model of experiment 3.1 for GET requests.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Throughput of the model of experiment 3.1 for SET requests.\relax }}{35}{figure.caption.27}}
\newlabel{fig:71_set}{{20}{35}{Throughput of the model of experiment 3.1 for SET requests.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}MVA algorithm implementation}{36}{subsection.7.4}}
